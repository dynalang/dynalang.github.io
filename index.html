<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta content="Instruct-NeRF2NeRF enables editing of a NeRF scene with a simple text instruction."
    name="description" />
  <meta content="Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions" property="og:title" />
  <meta content="Instruct-NeRF2NeRF enables editing of a NeRF scene with a simple text instruction."
    property="og:description" />
  <meta content="https://instruct-nerf2nerf.github.io/data/open_graph.png" property="og:image" />
  <meta content="Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions" property="twitter:title" />
  <meta content="Instruct-NeRF2NeRF enables editing of a NeRF scene with a simple text instruction."
    property="twitter:description" />
  <meta content="https://instruct-nerf2nerf.github.io/data/open_graph.png" property="twitter:image" />
  <meta property="og:type" content="website" />
  <meta content="summary_large_image" name="twitter:card" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
  <meta name="google-site-verification" content="sdz4d86QkTWaWHiWkS9mtiln38Bu0wirf94l-z1MkhQ" />


  <title>Learning to Model the World with Language</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-87HN038KJT"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-87HN038KJT');
  </script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Asap:wght@700&family=Source+Sans+3&display=swap" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js"></script>
  <script src="script.js" type="text/javascript"></script>

  <link href="style.css" rel="stylesheet" type="text/css" />

  <link href="data/icons/wand_black.svg" rel="icon" media="(prefers-color-scheme: light)" />
  <link href="data/icons/wand_white.svg" rel="icon" media="(prefers-color-scheme: dark)" />

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>


  <div class="section">
    <div class="container">
      <div class="title-row">
        <h1 class="title">Learning to Model the World with Language<h1>
      </div>
      <div class="row">
        <div class="author-col">
          <a href="https://www.jessylin.com/" target="_blank" class="author-text">
            Jessy Lin
          </a>
        </div>
        <div class="author-col">
          <a href="https://www.yuqingd.github.io/" target="_blank" class="author-text">
            Yuqing Du
          </a>
        </div>
        <div class="author-col">
          <a href="https://aliengirlliv.github.io/oliviawatkins/" target="_blank" class="author-text">
            Olivia Watkins
          </a>
        </div>
        <div class="author-col">
          <a href="https://danijar.com/" target="_blank" class="author-text">
            Danijar Hafner
            <span class="superscript"></span>
          </a>
        </div>
      </div>
      <div class="row">
        <div class="author-col">
          <a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank" class="author-text">
            Pieter Abbeel
          </a>
        </div>
        <div class="author-col">
          <a href="https://people.eecs.berkeley.edu/~klein/" target="_blank" class="author-text">
            Dan Klein
          </a>
        </div>
        <div class="author-col">
          <a href="https://people.eecs.berkeley.edu/~anca/" target="_blank" class="author-text">
            Anca Dragan
          </a>
        </div>
      </div>

      </div>
      <p id="uc-berkeley">UC Berkeley</h1>

      <div class="row">
        <a class="link-button" href="https://arxiv.org/abs/2303.12789" target="_blank" class="link-block">Paper</a>
        <a class="link-button" href="https://github.com/jlin816/dynalang" class="link-block">Code</a>
      </div>
      <p class="tldr">
        <b>TL;DR</b>:
        Dynalang learns from diverse types of language beyond instructions to solve tasks by learning a world model with language.
      </p>
      <video id="main-video" muted autoplay controls playsinline loop>
        <source id="mp4" src="data/videos/teaser.mp4" type="video/mp4">
      </video>

      <div id="content">
        <h2 class="section-header">Overview</h2>
        <div class="paragraph">
          <p>
          To interact with humans in the world, agents need to understand the diverse types of language that people use, relate them to the visual world, and act based on them. While current agents learn to execute simple language instructions from task rewards, we aim to build agents that leverage diverse language that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that language helps agents predict the future: what will be observed, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning objective. We present Dynalang, an agent that learns a multimodal world model that predicts future text and image representations and learns to act from imagined model rollouts. Unlike traditional agents that use language only to predict actions, Dynalang acquires rich language understanding by using past language also to predict future language, video, and rewards. In addition to learning from online interaction in an environment, Dynalang can be pretrained on datasets of text, video, or both without actions or rewards. From using language hints in grid worlds to navigating photorealistic scans of homes, Dynalang utilizes diverse types of language to improve task performance, including environment descriptions, game rules, and instructions.
          </p>
        </div>

        <h2 class="section-header">How It Works</h2>
        <div>
          <img class="wide-img" src="static/images/model.png" alt="Dynalang Model Architecture">
          <div class="paragraph">
            TODO
          </div>
        </div>

        <h2 class="section-header">HomeGrid: Language Hints</h2>
        <div class="paragraph">
        We introduce HomeGrid, a new environment where agents receive language hints in addition to instructions that describe parts of the environment that .
        - dynalang learns to ground even without explicit paired signal, just because it helps future prediction
        - dynalang outperforms
        </div>

        <img class="wide-img" src="static/images/homegrid_bars.png" alt="HomeGrid Results">
        <p class="caption">Dynalang learns to use all types of language to achieve higher task performance, and particularly excels at using language hints which are otherwise difficult to ground to the environment.</p>
        <div class="videos">
          <video muted autoplay controls playsinline loop>
            <source id="mp4" src="data/videos/homegrid_future.mp4" type="video/mp4">
          </video>
          <video muted autoplay controls playsinline loop>
            <source id="mp4" src="data/videos/homegrid_corrections.mp4" type="video/mp4">
          </video>
          <video muted autoplay controls playsinline loop>
           <source id="mp4" src="data/videos/homegrid_dyn.mp4" type="video/mp4">
          </video>
        </div>
        <div class="row">
          <p>
        </div>

        <h2 class="section-header">Messenger: Game Manuals</h2>
        <img class="wide-img" style="width: 75%" src="static/images/messenger_curves.png" alt="Messenger Results">
        <div class="videos">
          <video muted autoplay controls playsinline loop>
            <source id="mp4" src="data/videos/s30.mp4" type="video/mp4">
          </video>
          <video muted autoplay controls playsinline loop>
            <source id="mp4" src="data/videos/s31.mp4" type="video/mp4">
          </video>
        </div>

        <h2 class="section-header">Habitat: Instruction Following</h2>
        <div class="img-by-text">
          <img class="sm-img" src="static/images/vln.png" alt="Vision-Language Navigation Results">
          <div>Hello this is a test testset awe jljawe laekjalj lawef kjawf </div>
        </div>
        <div class="videos">
          <video muted autoplay controls playsinline loop>
            <source id="mp4" src="data/videos/vln1.mp4" type="video/mp4">
          </video>
          <video muted autoplay controls playsinline loop>
            <source id="mp4" src="data/videos/vln0.mp4" type="video/mp4">
          </video>
          <video muted autoplay controls playsinline loop>
            <source id="mp4" src="data/videos/vln2.mp4" type="video/mp4">
          </video>
        </div>

        <h2 class="section-header">LangRoom: Grounded Language Generation</h2>
        <div class="img-by-text">
          <img class="sm-img" src="static/images/langroom.png" alt="LangRoom Results">
          <div>Hello this is a test testset awe jljawe laekjalj lawef kjawf </div>
        </div>

        <h2 class="section-header">Text Pretraining</h2>
        <img class="sm-img" src="static/images/text_pretrain_all.png" alt="LangRoom Results">


        <div class="citation add-top-padding">
          <h1 id="abstract"> Citation </h1>
          <pre id="codecell0">@article{lin2023dynalang,
          &nbsp;author = {Lin, Jessy and Du, Yuqing and Watkins, Olivia and Hafner, Danijar and Abbeel, Pieter and Klein, Dan and Dragan, Anca},
          &nbsp;title = {Learning to Model the World with Language},
          &nbsp;booktitle = {arXiv preprint TODO},
          &nbsp;year = {2023},
          } </pre>
        </div>
      </div>

    </div>
  </div>
</body>

</html>
